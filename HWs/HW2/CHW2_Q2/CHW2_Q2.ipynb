{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Computer Homework 2\n",
    "## 2: Classification Models\n",
    "In this question, you will get familiar with classification models such as Linear Regression and Naive Bayes and train them on the given data-sets.       \n",
    "sklearn is a powerful library for training machine learning models. In this homework we shall use this library to build/train machine learning models.   \n",
    "\n",
    "You are only required to write code in the sections marked with `# TODO:`   \n",
    "Feel free to contact me via telegram if you have any question: @mamin_rami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question you will work with a data-set containig data to detect fake banknotes. The data has four columns(features). Each feature is extracted by performing some image processing techniques on the banknotes. You will use machine learning models on the data-set to differentiate between real and fake banknotes.   \n",
    "In the following section, you must read the data using pandas library and do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read the data_banknote_authentication.csv file using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, the data we work with is not clean. We need to preprocess it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete all rows containing a NaN value \n",
    "# Hint: use dropna command from pandas library \n",
    "\n",
    "# Extract X (the first four columns of data) and y (the last column of data) as numpy arrays\n",
    "\n",
    "# split data between train and test with 70% of data as train data and the rest as test data\n",
    "# Hint: use train_test_split command from sklearn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, a machine learning model may have parameters. The model learns these parameters by optimizing some objective function. Hence, some optimization algorithms are used to learn these parameters.       \n",
    "For these algorithms to perform well, it is better to normalize our features to have zero mean and unit variance.      \n",
    "In this section you will standardize the data to zero mean and unit variance.      \n",
    "Use `StandardScaler` class from `sklearn` library for this purpose.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: standardize both train and test data-set\n",
    "# Attention: you have to standardize based on training data-set( the .fit command should only be called upon trainig set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you must write a function to calculate accuracy, precision, recall and F1 score.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_score(y_true, y_pred):\n",
    "    # TODO\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will get into the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train a Logistic Regression model on the trainig data using sklearn library\n",
    "# Warning: Remember to use the scaled data\n",
    "\n",
    "\n",
    "# TODO: report the performance of the model on the test set using the performance_score function\n",
    "# Warning: Remember to use the scaled data\n",
    "\n",
    "\n",
    "# TODO: train a Gaussian Naive Bayes model on the trainig data using sklearn library\n",
    "# Warning: Remember to use the scaled data\n",
    "\n",
    "\n",
    "# TODO: report the performance of the model on the test set using the performance_score function\n",
    "# Warning: Remember to use the scaled data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
