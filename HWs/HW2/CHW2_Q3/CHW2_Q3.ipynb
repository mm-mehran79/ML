{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Computer Homework 2\n",
    "## 3: Regression Models\n",
    "In this question, you will implement linear basis function regression with polynomial and Gaussian basis functions. The task is to predict the median house value from features describing a town.    \n",
    "\n",
    "You are only required to write code in the sections marked with `# TODO:` \n",
    "Feel free to contact me via telegram if you have any question: @PouyaSha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The housing dataset is available in `housing.data` file. Load the dataset and normalize the features and target to have zero mean and unit variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root):\n",
    "    # TODO Load the data given the root. Note: t is the target output and X is the input features.\n",
    "    return X, t\n",
    "\n",
    "def normalize_data(X, X_ref):\n",
    "    # TODO This function Normalizes the data in X using the mean and variance of the data in X_ref.\n",
    "    #  If X_ref=X, then X_n is the normalized X to have zero mean and unit variance.\n",
    "    return X_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = # TODO dataset path\n",
    "X, t = load_data(root)\n",
    "X_ref, t_ref = # TODO\n",
    "X_n = normalize_data(X, X_ref)\n",
    "t_n = normalize_data(t, t_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Basis Function\n",
    "In this section, you are supposed to implement linear regression using polynomial basis functions. Use only monomials of a single variable and no cross-terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function that normalizes all data attributes to $N(0,1)$. The *_T notation represents training set and *_Q represents the query/test set. Note that only training data can be used for learning the normalization transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_all(X_T, t_T, X_Q, t_Q):\n",
    "    return Xn_T, tn_T, Xn_Q, tn_Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete this half-written function that generates the feature vectors for input points X. The input X can be one or more points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_features(X, basis, *args):\n",
    "    assert basis in ['polynomial', 'gaussian'], 'Unknown basis type'\n",
    "    if basis == 'polynomial':\n",
    "        max_degree = args[0]\n",
    "        phi = # TODO generated feature vectors for input points\n",
    "    elif basis == 'gaussian':\n",
    "        mu, s = args[0], args[1]\n",
    "        phi = # TODO generated feature vectors for input points\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function for degree-n polynomial regression using training data (X_T,\n",
    "t_T) at query point (X_Q). The output is the regression result (t_Q), and the regression\n",
    "weights (W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(X_T, t_T, X_Q, n):\n",
    "    # TODO implement the function\n",
    "    return t_Q, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code for testing polynomial regression as following:\n",
    "Using the first 100 points as training data, and the remainder as testing data, fit a polynomial\n",
    "basis function regression for degree 1 to degree 7 polynomials. Do not use any regularization.\n",
    "Plot training error and test error (in RMS error) versus polynomial degree.\n",
    "Put this plot, along with a brief comment on what you see, in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO evaluate your functions on the data as explained above\n",
    "# TODO plot the RMS error vs polynomial degrees for the training and testing data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(TODO: YOUR ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your polynomial regression using a degree 1 polynomial. Examine the learned weights.\n",
    "What value is chosen for w5, the weight on the 5th feature (average number of rooms per\n",
    "dwelling)? What value is chosen for the weight on the 7th feature (weighted distance to five\n",
    "Boston employment centers)? The weights on the model are trained for normalized attributes,\n",
    "X_n. What are the equivalent weights for the original attributes, i.e. X? Do these 2 weights\n",
    "seem reasonable?\n",
    "\n",
    "Put the values of all weights and your comments on weights for the 5th and 7th\n",
    "features in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO evaluate your functions as explained above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(TODO: YOUR ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is diffcult to visualize the results of high-dimensional regression. Instead, only use one of\n",
    "the features (use X_n(:,2)) and again perform polynomial regression. Produce plots of the\n",
    "training data points, learned polynomial, and test data points. Do not forget the normalization.\n",
    "\n",
    "Put 3 of these plots, for interesting (low-order, high-order polynomials) results, in\n",
    "your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create a script as explained above\n",
    "# Note: X_n is 1-d,  X_train, X_test, t_train, t_test should all be 1-d, and need to be defined as well. \n",
    "# TODO plot a curve showing learned function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement L2-regularized regression using the first 100 points, and only the 2nd feature. Fit\n",
    "a degree 8 polynomial using each value in 0, 0.01, 0.1, 1, 10, 100, 1000 for λ. Use 10-fold\n",
    "cross-validation to decide on the best value of λ. Produce a plot of average validation set error\n",
    "versus the regularizing constant λ. Use a semilogx plot, putting the regularizing constant λ on\n",
    "a log scale. Report (λ = 0) as a separate horizontal line as a baseline.\n",
    "\n",
    "Put this plot in your report, and note which regularizing constant λ you would\n",
    "choose for the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create a script as explained above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Basis Function\n",
    "\n",
    "Now we modify our regression to support Gaussian basis functions. You may use the supplied\n",
    "function dist2. For the centers µj use randomly chosen training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist2(x, c):\n",
    "    #\tDescription\n",
    "    #\tD = DIST2(X, C) takes two matrices of vectors and calculates the\n",
    "    #\tsquared Euclidean distance between them.  Both matrices must be of\n",
    "    #\tthe same column dimension.  If X has M rows and N columns, and C has\n",
    "    #\tL rows and N columns, then the result has M rows and L columns.  The\n",
    "    #\tI, Jth entry is the  squared distance from the Ith row of X to the\n",
    "    #\tJth row of C.\n",
    "    ndata, dimx = x.shape\n",
    "    ncentres, dimc = c.shape\n",
    "    assert dimx == dimc, 'Data dimension does not match dimension of centres'\n",
    "    d2 = np.zeros((ndata, ncentres))\n",
    "    for i, row in enumerate(x):\n",
    "        d2[i] = (c - row)**2\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function for Gaussian regression. Your implementation would be exactly\n",
    "similar to polynomial_regression function, expect using Gaussian features by calling regression_features function with basis=’gaussian’ input. The matrix µ is the list of Gaussian center\n",
    "points, and the scalar value s shows the constant Gaussian variance, which represents the width\n",
    "of the kernel. We will call this function with constant s=2, but keep s as an input parameter so\n",
    "that you can play with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_regression(X_T, t_T, X_Q, mu, s):\n",
    "    # TODO implement the function\n",
    "    return t_Q, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to polynomial regression script, create a script for the following: Use the first\n",
    "100 points as training data, and the remainder as testing data. Fit a Gaussian basis function\n",
    "regression using 5, 15, 25, ··· , 95 basis functions (Generate a random permutation of points\n",
    "and pick the first K points as the center of the basis functions). Do not use any regularization.\n",
    "Plot the training error and test error (in RMS error) versus number of basis functions. \n",
    "\n",
    "Put this plot, along with a brief comment on what you see, in your report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO evaluate your functions on the data as explained above\n",
    "# TODO plot the RMS error vs polynomial degrees for the training and testing data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(TODO: YOUR ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to polynomial regression reg.m, Create a script for the following:\n",
    "Implement L2-regularized regression. Again, use the first 100 points (do not only use the\n",
    "second feature, use them all). Fit a regression model with 90 basis functions using each value\n",
    "in 0, 0.01, 0.1, 1, 10, 100, 1000 for λ. Use 10-fold cross-validation to decide on the best value\n",
    "of λ. Produce a plot of average validation set error versus the regularizing constant λ. Use a\n",
    "semilogx plot, putting the regularizing constant λ on the log scale. The unregularized result,\n",
    "i.e. (λ = 0), will not appear on the log-scale plot. You can either add it as a separate line as\n",
    "a baseline, or report this number separately\n",
    "\n",
    "Put this plot on your report, and note which regularizing constant λ you would\n",
    "choose from the cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create a script as explained above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
